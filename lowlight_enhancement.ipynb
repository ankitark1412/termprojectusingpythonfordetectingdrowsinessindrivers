{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lowlight_enhancement.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"N0P9Yoqro9Vb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618570793929,"user_tz":-330,"elapsed":27162,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}},"outputId":"175a2fe1-87ac-4a95-9214-db50bbcf0b60"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsBYKmh0pMsH","executionInfo":{"status":"ok","timestamp":1618570798809,"user_tz":-330,"elapsed":1327,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}},"outputId":"4afa3b69-042a-46d1-f89b-586f2e72fca2"},"source":["cd drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzLZeqMMpN1b","executionInfo":{"status":"ok","timestamp":1618570804322,"user_tz":-330,"elapsed":2081,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}},"outputId":"ebc7c71c-e364-4ec7-9189-54bb40093753"},"source":["cd MyDrive"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ul82OLjc67Wg","executionInfo":{"status":"ok","timestamp":1618570808503,"user_tz":-330,"elapsed":2551,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}},"outputId":"bc1c5050-4bd2-419a-de86-88c367bc303e"},"source":["cd driver-safety"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/driver-safety\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUkv0JZGpQDp","executionInfo":{"status":"ok","timestamp":1618570811096,"user_tz":-330,"elapsed":728,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}},"outputId":"5440d141-9bca-4575-b390-f0acc1ca68e8"},"source":["cd Zero-DCE-1-master"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/driver-safety/Zero-DCE-1-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwkszuExpTnS","executionInfo":{"status":"ok","timestamp":1618570814157,"user_tz":-330,"elapsed":1600,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}},"outputId":"67b21c8c-d099-4aac-dabc-ac27f1cda46c"},"source":["cd Zero-DCE_code"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/driver-safety/Zero-DCE-1-master/Zero-DCE_code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rb1TpXzatmqT","executionInfo":{"status":"ok","timestamp":1618570829447,"user_tz":-330,"elapsed":11057,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import os\n","import sys\n","import argparse\n","import time\n","import dataloader\n","import model\n","import numpy as np\n","from torchvision import transforms\n","from PIL import Image\n","import glob\n"," \n","def lowlight(image_path):\n","    os.environ['CUDA_VISIBLE_DEVICES']='0'\n","    data_lowlight = Image.open(image_path)\n"," \n"," \n"," \n","    data_lowlight = (np.asarray(data_lowlight)/255.0)\n"," \n"," \n","    data_lowlight = torch.from_numpy(data_lowlight).float()\n","    data_lowlight = data_lowlight.permute(2,0,1)\n","    data_lowlight = data_lowlight.cuda().unsqueeze(0)\n"," \n","    DCE_net = model.enhance_net_nopool().cuda()\n","    DCE_net.load_state_dict(torch.load('snapshots/Epoch99.pth'))\n","    \n","    _,enhanced_image,_ = DCE_net(data_lowlight)\n"," \n","    result_path = 'a.jpg'\n","    torchvision.utils.save_image(enhanced_image, result_path)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFBziqzVLnGC","executionInfo":{"status":"ok","timestamp":1618570838936,"user_tz":-330,"elapsed":7327,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}}},"source":["import cv2\n","import dlib\n","import numpy as np\n","import os\n","from scipy.spatial import distance\n","from google.colab.patches import cv2_imshow\n"," \n"," \n","def calculate_eye(eye):\n","        A = distance.euclidean(eye[1], eye[5])\n","        B = distance.euclidean(eye[2], eye[4])\n","        C = distance.euclidean(eye[0], eye[3])\n","        eye_aspect_ratio = (A+B)/(2.0*C)\n","        return eye_aspect_ratio\n"," \n","def underlayer_calculate_lips(lips):\n","        A = distance.euclidean(lips[1], lips[7])\n","        B = distance.euclidean(lips[3], lips[5])\n","        C = distance.euclidean(lips[2], lips[6])\n","        D = distance.euclidean(lips[0], lips[4])\n","        lips_aspect_ratio = (A+B+C)/(3.0*D)\n","        return lips_aspect_ratio\n"," \n","def upperlayer_calculate_lips(lips):\n","        A = distance.euclidean(lips[1], lips[11])\n","        B = distance.euclidean(lips[2], lips[10])\n","        C = distance.euclidean(lips[3], lips[9])\n","        D = distance.euclidean(lips[4], lips[8])\n","        E = distance.euclidean(lips[5], lips[7])\n","        F = distance.euclidean(lips[0], lips[6])\n","        lips_aspect_ratio = (A+B+C+D+E)/(5.0*F)\n","        return lips_aspect_ratio\n","        \n","hog_face_detector = dlib.get_frontal_face_detector()\n","dlib_facelandmark = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n"," \n","# Text settings\n","font = cv2.FONT_HERSHEY_COMPLEX\n","font_scale = 0.5\n"," \n","alpha=2\n","beta=50\n"," \n","# Initializations\n","sleep_score1=0\n"," \n","sleep_score2=0\n","frame_count=0\n","Initial_nose_tip_X=[]\n","count_X=0\n","average_nose_X = 0"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLw_P4fn-3Gb","executionInfo":{"status":"ok","timestamp":1618579633575,"user_tz":-330,"elapsed":7925,"user":{"displayName":"Ankita Radhakrishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk4vK68a5aw67h6oBGB0x2y1VY-flsfq1m32aL8g=s64","userId":"04215707433058404265"}},"outputId":"cf7aae68-4473-4f8c-816b-e1f6225d2e49"},"source":["cap = cv2.VideoCapture('Videos for Accuracy - lowlight/Abhishek/Blinking/abhishek_18')\n","# Check if camera opened successfully\n","if (cap.isOpened()== False): \n","  print(\"Error opening video  file\")\n"," \n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n","#name = np.zeros((height,width,3), np.uint8) \n"," \n"," \n","frames = []\n"," \n"," \n","# Read until video is completed\n","while(cap.isOpened()):\n","      \n","  # Capture frame-by-frame\n","  ret, frame = cap.read()\n","  if ret == True:\n","   \n","    # Display the resulting frame\n"," \n","    cv2.imwrite('x.jpg',frame)\n","    #saving the image to the same directory\n"," \n","    lowlight('x.jpg')\n","    #performing the enhancement on each frame\n"," \n","    frame = cv2.imread('a.jpg')\n","    #reading the enhanced frame from the folder\n"," \n","    frames.append(frame)\n"," \n","    os.remove('x.jpg')\n","    os.remove('a.jpg')\n","    #removing the frame and the enhanced frame from the folder each time\n","    \n","    height,width = frame.shape[:2]\n","    name = np.zeros((height,width,3), np.uint8)\n","    #creating a black filled rectangle which fills the entire frame\n"," \n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n"," \n","    faces = hog_face_detector(gray)\n","    for face in faces:\n","        face_landmarks = dlib_facelandmark(gray,face)\n","  \n","        face_landmarks = dlib_facelandmark(gray,face)\n"," \n","        X=face_landmarks.part(34).x\n","        Y=face_landmarks.part(34).y\n","        \n","        \n","        if(len(Initial_nose_tip_X) < 10):\n","                Initial_nose_tip_X.append(X)\n","        if(len(Initial_nose_tip_X)==10):\n","                average_nose_X = int(sum(Initial_nose_tip_X)/10)\n","        leftEye = []\n","        rightEye = []\n"," \n","        if(X>(average_nose_X + 100)):\n","                count_X=count_X+1\n","        if(X<(average_nose_X - 75)):\n","                count_X=count_X+1\n","        if(X<(average_nose_X+100) and X>(average_nose_X - 75)):\n","                count_X=count_X-1\n","        if(count_X<0):\n","                count_X=0\n","        if(count_X > 40):\n","                cv2.putText(name, \"ALERT!\", (10,50), font, 2, (255, 255, 255), 4)\n","                \n","        if(count_X < 40):\n","                cv2.putText(name,'Pose Error:'+str(count_X),(width-250,height-160), font, 1,(255,255,255),1,cv2.LINE_AA)\n"," \n","        for n in range(36,42):\n","                x = face_landmarks.part(n).x\n","                y = face_landmarks.part(n).y\n","                leftEye.append((x,y))\n","                next_point = n+1\n","                if n == 41:\n","                        next_point = 36\n","                x2 = face_landmarks.part(next_point).x\n","                y2 = face_landmarks.part(next_point).y\n"," \n","        for n in range(42,48):\n","                x = face_landmarks.part(n).x\n","                y = face_landmarks.part(n).y\n","                rightEye.append((x,y))\n","                next_point = n+1\n","                if n == 47:\n","                        next_point = 42\n","                x2 = face_landmarks.part(next_point).x\n","                y2 = face_landmarks.part(next_point).y\n"," \n"," \n","        underlips = []\n","        for n in range(60,68):\n","                x = face_landmarks.part(n).x\n","                y = face_landmarks.part(n).y\n","                underlips.append((x,y))\n","                next_point = n+1\n","                if n == 67:\n","                        next_point = 60\n","                x2 = face_landmarks.part(next_point).x\n","                y2 = face_landmarks.part(next_point).y        \n","        upperlips = []\n","        for n in range(48,60):\n","                x = face_landmarks.part(n).x\n","                y = face_landmarks.part(n).y\n","                upperlips.append((x,y))\n","                next_point = n+1\n","                if n == 59:\n","                        next_point = 48\n","                x2 = face_landmarks.part(next_point).x\n","                y2 = face_landmarks.part(next_point).y\n"," \n","        left_eye = calculate_eye(leftEye)\n","        right_eye = calculate_eye(rightEye)\n"," \n","        EYE = (left_eye+right_eye)/2\n","        EYE = round(EYE,2)\n"," \n","        upper_lips = upperlayer_calculate_lips(upperlips)\n"," \n","        under_lips = underlayer_calculate_lips(underlips)\n","        \n"," \n","        LIPS = (under_lips + upper_lips) \n","        LIPS = round(LIPS,2)\n","        \n","        if EYE < 0.24:\n","                sleep_score1=sleep_score1+1\n","                cv2.putText(name,\"Closed eyes\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n","        else:\n","                sleep_score1=sleep_score1-1\n","                cv2.putText(name,\"Open eyes\",(10,height-20), font, 1,(255, 255, 255),1,cv2.LINE_AA)\n","        \n","        if LIPS > .35:\n","                sleep_score2=sleep_score2+1\n","                cv2.putText(name,\"Yawning\",(10,height-80), font, 1,(255,255,255),1,cv2.LINE_AA)\n","                if (frame_count==0):\n","                        frame_count=frame_count+1   #it will initiate the counting of total number of frames once we will start yawning\n","                \n","        else:\n","                cv2.putText(name,\"Not Yawning\",(10,height-80), font, 1,(255,255,255),1,cv2.LINE_AA)\n","        \n","        if(sleep_score1<0):\n","                sleep_score1=0\n"," \n","        cv2.putText(name,'Blinking:'+str(sleep_score1),(width-200,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n","        if(sleep_score1>5):\n","                #person is feeling sleepy so we beep the alarm\n","                cv2.putText(name, \"ALERT!\", (10,50), font, 2, (255, 255, 255), 4)\n","                \n","         \n","        cv2.putText(name,'Yawning:'+str(sleep_score2),(width-200,height-80), font, 1,(255,255,255),1,cv2.LINE_AA)\n"," \n","        if(sleep_score2)>50:         #For demonstration purpose it is 50 \n","                #person is feeling sleepy so we beep the alarm\n","                cv2.putText(name, \"ALERT!\", (10,50), font, 2, (255, 255, 255), 4)\n"," \n","              \n","        if(frame_count>0):\n","                frame_count=frame_count+1\n"," \n","        if (frame_count > 54000):          #54000=30*60*30\n","                sleep_score2=0\n","                frame_count=0\n"," \n","    \n","    cv2_imshow(name)\n"," \n","  \n","    # Press Q on keyboard to  exit\n","    if cv2.waitKey(25) & 0xFF == ord('q'):\n","      break\n","   \n","  # Break the loop\n","  else: \n","    break\n","    \n"," \n","out = cv2.VideoWriter('abhishek_18_enhanced.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 10, (width, height))\n","for i in frames:\n","    out.write(i)\n"," \n","out.release()\n"," \n","# When everything done, release \n","# the video capture object\n","cap.release()\n","   \n","# Closes all the frames\n","cv2.destroyAllWindows()"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Error opening video  file\n"],"name":"stdout"}]}]}